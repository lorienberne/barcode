{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(root_dir):\n",
    "    original_dir = os.path.join(root_dir, \"original\")\n",
    "    degraded_dir = os.path.join(root_dir, \"degraded\")\n",
    "    \n",
    "    original_images = [os.path.join(original_dir, img) for img in os.listdir(original_dir)]\n",
    "    degraded_images = [os.path.join(degraded_dir, img) for img in os.listdir(degraded_dir)]\n",
    "    print(degraded_images[:5])\n",
    "    # Mapping original to degraded\n",
    "    mapping = {}\n",
    "    for orig_path in original_images:\n",
    "        base_name = os.path.basename(orig_path)\n",
    "        # print(base_name)\n",
    "        idx, barcode, _ = base_name.split('_')\n",
    "        # print([img for img in degraded_images])\n",
    "        degraded_versions = [img for img in degraded_images if img.startswith(f\"./data/tmp/degraded/{idx}_{barcode}\")]\n",
    "        mapping[orig_path] = degraded_versions\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "# Assuming '/data/tmp' is your root directory\n",
    "root_dir = './data/tmp'\n",
    "image_paths = load_image_paths(root_dir)\n",
    "\n",
    "# Splitting into train and test sets\n",
    "original_images = list(image_paths.keys())\n",
    "train_orig, test_orig = train_test_split(original_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating train and test mappings\n",
    "train_mapping = {orig: image_paths[orig] for orig in train_orig}\n",
    "test_mapping = {orig: image_paths[orig] for orig in test_orig}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, mapping, transform=None):\n",
    "        self.mapping = mapping\n",
    "        self.transform = transform\n",
    "        self.original_images = list(mapping.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.original_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        orig_path = self.original_images[idx]\n",
    "        degraded_paths = self.mapping[orig_path]\n",
    "        \n",
    "        # Example: loading the first degraded image\n",
    "        degraded_path = random.choice(degraded_paths) # Randomly select one for variability\n",
    "        orig_image = Image.open(orig_path)\n",
    "        degraded_image = Image.open(degraded_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            orig_image = self.transform(orig_image)\n",
    "            degraded_image = self.transform(degraded_image)\n",
    "        \n",
    "        return degraded_image, orig_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert images to binary\n",
    "def to_binary(tensor, threshold=0.5):\n",
    "    # Convert to grayscale by averaging the channels\n",
    "    grayscale = tensor.mean(dim=0, keepdim=True)\n",
    "    # Apply threshold\n",
    "    binary = (grayscale > threshold).float()\n",
    "    return binary\n",
    "\n",
    "# Create the transform pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: to_binary(x))\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(train_mapping, transform=transform)\n",
    "test_dataset = ImageDataset(test_mapping, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a tensor to a numpy array\n",
    "def imshow(img):\n",
    "    img = img.numpy() # Convert tensor to numpy array\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0))) # Convert from CxHxW to HxWxC\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter) # Use next() to get the next batch\n",
    "\n",
    "# Show images for the first image in the batch\n",
    "print(images[0].unsqueeze(0).shape)\n",
    "imshow(torchvision.utils.make_grid(images[0].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    print(data[0].shape)\n",
    "    print(data[0][0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    " \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    " \n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for degraded_images, original_images in loop:\n",
    "        degraded_images = degraded_images.to(device)\n",
    "        original_images = original_images.to(device)\n",
    "        \n",
    "        reconstructed_images = model(degraded_images)\n",
    "        loss = criterion(reconstructed_images, original_images)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    average_loss = total_loss / num_batches\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}\")\n",
    "    \n",
    "    # Evaluate every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # Inference mode, gradients not calculated\n",
    "            val_loss = 0\n",
    "            val_batches = 0\n",
    "            for degraded_images, original_images in test_loader:\n",
    "                degraded_images = degraded_images.to(device)\n",
    "                original_images = original_images.to(device)\n",
    "                \n",
    "                reconstructed_images = model(degraded_images)\n",
    "                loss = criterion(reconstructed_images, original_images)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "            \n",
    "            average_val_loss = val_loss / val_batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
